{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09ee3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a06175",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "341868f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vacancies_id(header:dict, param:dict=None, URL:str='https://api.hh.ru/vacancies', per_page:int=100, time_delay:float=0)->json:\n",
    "    sleep(time_delay)\n",
    "    return requests.get(url=URL, headers=header, params=param).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d489b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_TITLE = ['Аналитик данных','BI','Системный аналитик', 'Бизнес-аналитик']\n",
    "\n",
    "USER_AGENT = dotenv_values(r'D:\\Dev\\_Projects\\hh_project\\.env')['USER_AGENT']\n",
    "# CACHE_FILE = dotenv_values(r'D:\\Dev\\_Projects\\hh_project\\.env')['CACHE_FILE']\n",
    "# PATH_TO_YANDEXDISC = dotenv_values(r'D:\\Dev\\_Projects\\hh_project\\.env')['PATH_TO_YANDEXDISC']\n",
    "\n",
    "BASE_URL='https://api.hh.ru/vacancies'\n",
    "\n",
    "PER_PAGE = 100\n",
    "\n",
    "header = {'User-Agent':USER_AGENT}\n",
    "param = {'professional_roles': JOB_TITLE,\n",
    "          'search_field': 'name',\n",
    "          'page': 0,\n",
    "          'per_page': PER_PAGE,\n",
    "          'only_with_salary': True,\n",
    "          'locale': 'RU'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dbf805",
   "metadata": {},
   "source": [
    "# Получение роли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17bd82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Профессиональная роль 'датасайенс' не найдена\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4518a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено вакансий: 81\n"
     ]
    }
   ],
   "source": [
    "PER_PAGE = 100  # Количество результатов на страницу\n",
    "\n",
    "params = {\n",
    "    'professional_role': ROLE_ID,  # Используем ID роли вместо текста\n",
    "    'page': 0,\n",
    "    'per_page': PER_PAGE,\n",
    "    'only_with_salary': True,\n",
    "    'locale': 'RU'\n",
    "}\n",
    "\n",
    "# Выполнение запроса\n",
    "url = \"https://api.hh.ru/vacancies\"\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    vacancies = response.json()\n",
    "    print(f\"Найдено вакансий: {vacancies['found']}\")\n",
    "    # Дальнейшая обработка данных...\n",
    "else:\n",
    "    print(f\"Ошибка запроса: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d845d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_VACANCIES = [\n",
    "    'BI-аналитик, аналитик данных',\n",
    "    'Аналитик',\n",
    "    'Бизнес-аналитик',\n",
    "    'Дата-сайентист',\n",
    "    'Продуктовый аналитик',\n",
    "    'Руководитель отдела аналитики',\n",
    "    'Сетевой инженер',\n",
    "    'Системный аналитик',\n",
    "    'Системный инженер'\n",
    "]\n",
    "\n",
    "DEFAULT_VACANCIES = [item.lower().strip() for item in DEFAULT_VACANCIES]\n",
    "\n",
    "\n",
    "roles = requests.get('https://api.hh.ru/professional_roles').json()\n",
    "result = []\n",
    "for category in roles.get('categories', []):\n",
    "    if category.get('id') == '11':\n",
    "        result.append(category)\n",
    "\n",
    "d = dict()\n",
    "for item in result[0].get('roles'):\n",
    "    if item.get('name').lower().strip() in DEFAULT_VACANCIES:\n",
    "        d[item.get('name')] = item.get('id')\n",
    "\n",
    "\n",
    "with open('test.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(d, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b070f5a1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1269f30",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_vacancies_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m param = {\u001b[33m'\u001b[39m\u001b[33mprofessional_roles\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mСистемный аналитик\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      2\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mpage\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0\u001b[39m,\n\u001b[32m      3\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mper_page\u001b[39m\u001b[33m'\u001b[39m: PER_PAGE,\n\u001b[32m      4\u001b[39m         \u001b[33m'\u001b[39m\u001b[33monly_with_salary\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      5\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mlocale\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mRU\u001b[39m\u001b[33m'\u001b[39m}\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m resp = \u001b[43mget_vacancies_id\u001b[49m(header, param, per_page=PER_PAGE)\n\u001b[32m      7\u001b[39m resp.get(\u001b[33m'\u001b[39m\u001b[33mitems\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33mprofessional_roles\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'get_vacancies_id' is not defined"
     ]
    }
   ],
   "source": [
    "param = {'professional_roles': 'Системный аналитик',\n",
    "        'search_field': 'name',\n",
    "        'page': 0,\n",
    "        'per_page': PER_PAGE,\n",
    "        'only_with_salary': True,\n",
    "        'locale': 'RU'}\n",
    "resp = get_vacancies_id(header, param, per_page=PER_PAGE)\n",
    "resp.get('items')[0].get('professional_roles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b89887c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Obsidian\\\\YandexDisk'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TO_YANDEXDISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d4cde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 3, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = get_vacancies_id(header, param, per_page=PER_PAGE)\n",
    "\n",
    "VAC_CNT = resp['found']\n",
    "PAGES_CNT = resp['pages']\n",
    "current_page = resp['page']\n",
    "VAC_CNT, PAGES_CNT, current_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c256b560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's all OK\n"
     ]
    }
   ],
   "source": [
    "vac_ids = []\n",
    "current_page = 0\n",
    "PAGES_CNT = 999\n",
    "\n",
    "while current_page <= PAGES_CNT-1:\n",
    "    resp = get_vacancies_id(header, param, per_page=PER_PAGE)\n",
    "    current_page = resp['page']\n",
    "    PAGES_CNT = resp['pages']\n",
    "\n",
    "    for item in resp['items']:\n",
    "        vac_ids.append(item['id'])\n",
    "\n",
    "    param['page'] = current_page + 1\n",
    "    resp = get_vacancies_id(header, param, per_page=PER_PAGE)\n",
    "    current_page = resp['page']\n",
    "\n",
    "\n",
    "print(\"It's all OK\" if len(set(vac_ids)) == VAC_CNT else f\"Smt went WRONG\\n{len(set(vac_ids))}___{VAC_CNT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2683beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skills_str(key_skills:list)->str:\n",
    "    '''Функция преобразования списка словарей требуемых скилов в строку'''\n",
    "    result = []\n",
    "    for skill in key_skills:\n",
    "        result.append(skill.get('name'))\n",
    "    return '; '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a16b637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_CACHE = {}\n",
    "updated_currency = False\n",
    "\n",
    "def get_curse_valute(valute: str) -> float:\n",
    "    global CURRENCY_CACHE, updated_currency\n",
    "\n",
    "    valute = valute.upper()\n",
    "\n",
    "    #исключения для написания валют на HH\n",
    "    exception_valute={'BYR':'BYN'} \n",
    "    if valute in exception_valute:\n",
    "        valute=exception_valute[valute]\n",
    "\n",
    "    CURRENCY_CACHE = {}\n",
    "    CACHE_FILE = r'resources/valute_cache.json'\n",
    "\n",
    "    if os.path.exists(CACHE_FILE):\n",
    "        with open(CACHE_FILE) as f:\n",
    "            CURRENCY_CACHE = json.load(f)\n",
    "    \n",
    "    if not updated_currency:\n",
    "        try:\n",
    "            #пробуем запросить курсы валют\n",
    "            res = requests.get(\"https://www.cbr-xml-daily.ru/daily_json.js\", timeout=3).json()\n",
    "            valutes = res.get('Valute', {})\n",
    "            \n",
    "            #обновим файл с кэшом\n",
    "            for code, data in valutes.items():\n",
    "                nominal = data.get('Nominal', 1)\n",
    "                value = data.get('Value')\n",
    "                if nominal and value:\n",
    "                    CURRENCY_CACHE[code] = value / nominal\n",
    "\n",
    "            #сохраним курс\n",
    "            with open(CACHE_FILE, 'w') as f:\n",
    "                json.dump(CURRENCY_CACHE, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            updated_currency = True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Error: Не удалось обновить курсы валют ({e})')\n",
    "\n",
    "    # Возвращаем запрошенную валюту (если есть в ответе)\n",
    "    if valute in CURRENCY_CACHE:\n",
    "        return CURRENCY_CACHE[valute]\n",
    "    \n",
    "    print(f'Error: Не удалось определить курс валюты {valute}')\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fbacaf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Получение описания вакансий...:   0%|          | 0/208 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Получение описания вакансий...: 100%|██████████| 208/208 [01:54<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Parsing done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "\n",
    "for vac_id in tqdm(vac_ids, desc='Получение описания вакансий...'):\n",
    "    try:\n",
    "        vac_annote = get_vacancies_id(header=header, URL=BASE_URL+f'/{vac_id}', time_delay=0.4)\n",
    "\n",
    "\n",
    "        employer = vac_annote.get('employer')\n",
    "        salary_range = vac_annote.get('salary_range', {})\n",
    "        mode = salary_range.get('mode', {}) if salary_range else {}\n",
    "        prof_roles = vac_annote.get('professional_roles', [])\n",
    "\n",
    "\n",
    "        # обработка гросс зарплаты\n",
    "        salary = vac_annote.get('salary')\n",
    "        salary_from = None\n",
    "        salary_to = None\n",
    "\n",
    "        if salary:\n",
    "            is_gross = salary.get('gross', True)\n",
    "            conversion_rate = 0.87 if is_gross else 1.0\n",
    "\n",
    "            if 'from' in salary and salary['from'] is not None:\n",
    "                salary_from = salary['from'] * conversion_rate\n",
    "\n",
    "            if 'to' in salary and salary['to'] is not None:\n",
    "                salary_to = salary['to'] * conversion_rate\n",
    "\n",
    "\n",
    "        #обработка других валют, перевод в рубли\n",
    "        currency = salary.get('currency')\n",
    "        if currency and currency != 'RUR':\n",
    "            \n",
    "            rate = get_curse_valute(currency)\n",
    "            \n",
    "            if salary_from is not None:\n",
    "                salary_from = round(salary_from * rate)\n",
    "            if salary_to is not None:\n",
    "                salary_to = round(salary_to * rate)\n",
    "\n",
    "\n",
    "        #обработка широты и долготы\n",
    "        address = vac_annote.get('address')\n",
    "        lat = address.get('lat') if address else None\n",
    "        lng = address.get('lng') if address else None\n",
    "        geo = f\"[{lat}, {lng}]\" if lat is not None and lng is not None else None\n",
    "\n",
    "        \n",
    "        #Определение грейда вакансии\n",
    "        name = vac_annote.get('name', '').lower()\n",
    "        if any(word in name for word in ['стажер', 'стажёр', 'интерн', 'помощник', 'intern', 'trainee']):\n",
    "            grade = 'Intern'\n",
    "        elif any(word in name for word in ['младший', 'junior', 'джуниор', 'начинающий']):\n",
    "            grade = 'Junior'\n",
    "        elif any(word in name for word in ['мидл', 'middle', 'средний', 'mid-level']):\n",
    "            grade = 'Middle'\n",
    "        elif any(word in name for word in ['сеньор', 'senior', 'старший', 'ведущий', 'опытный']):\n",
    "            grade = 'Senior'\n",
    "        elif any(word in name for word in ['тимлид', 'teamlead', 'руководитель', 'lead', 'главный']):\n",
    "            grade = 'Team Lead'\n",
    "        else:\n",
    "            grade = 'Middle'\n",
    "\n",
    "\n",
    "        row = {\n",
    "            'vac_id': vac_annote.get('id'),\n",
    "            'vac_name': vac_annote.get('name'),\n",
    "            'grade':grade,\n",
    "            'city': vac_annote.get('area', {}).get('name'),\n",
    "            'geo': geo,\n",
    "            'published_at': vac_annote.get('published_at'),\n",
    "            'archived': vac_annote.get('archived'),\n",
    "            'employer_id': employer.get('id') if employer else None,\n",
    "            'emp_name': vac_annote.get('employment', {}).get('name'),\n",
    "            'addres': address.get('raw') if address else None,\n",
    "            'is_accredited': employer.get('accredited_it_employer') if employer else None,\n",
    "            'is_trusted': employer.get('trusted') if employer else None,\n",
    "            # 'salary_from': salary.get('from') if salary else None,\n",
    "            'salary_from' : salary_from,\n",
    "            # 'salary_to': salary.get('to') if salary else None,\n",
    "            'salary_to' : salary_to,\n",
    "            'currency': salary.get('currency') if salary else None,\n",
    "            'gross': salary.get('gross') if salary else None,\n",
    "            'mode_name': mode.get('name'),\n",
    "            'frequency': mode.get('frequency'),\n",
    "            'prof_role': prof_roles[0].get('name') if prof_roles else None,\n",
    "            'schedule_name': vac_annote.get('schedule', {}).get('name'),\n",
    "            'insider_interview': vac_annote.get('insider_interview'),\n",
    "            'response_letter_required': vac_annote.get('response_letter_required'),\n",
    "            'experience': vac_annote.get('experience', {}).get('name'),\n",
    "            'key_skills': get_skills_str(vac_annote.get('key_skills')) if vac_annote.get('key_skills') else None,\n",
    "            'has_test': vac_annote.get('has_test'),\n",
    "            'description': vac_annote.get('description'),\n",
    "            'url':vac_annote.get('alternate_url')\n",
    "        }\n",
    "        data_list.append(row)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Error processing vac_id {vac_id}: {e}')\n",
    "\n",
    "# Создаем DataFrame одним вызовом\n",
    "full_df = pd.DataFrame(data_list)\n",
    "print('Success: Parsing done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "031e1c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"geoapi\", timeout=10)\n",
    "\n",
    "def load_cache():\n",
    "    # Загрузка кэша из файла\n",
    "    if os.path.exists(CACHE_FILE):\n",
    "        try:\n",
    "            with open(CACHE_FILE, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        except:\n",
    "            return {}\n",
    "    print('⚠️ Warning: Cache file not found')\n",
    "    return {}\n",
    "\n",
    "\n",
    "def get_geopoints(city: str, cache: dict) -> str:\n",
    "    # Получение координат с использованием кэша\n",
    "    if not city or pd.isna(city):\n",
    "        return None\n",
    "    \n",
    "    # Проверяем кэш\n",
    "    if city in cache:\n",
    "        return cache[city]\n",
    "    \n",
    "    # Геокодирование если нет в кэше\n",
    "    try:\n",
    "        location = geolocator.geocode(f\"{city}\")\n",
    "        if location:\n",
    "            result = f'[{str(location.latitude)}, {str(location.longitude)}]'\n",
    "        else:\n",
    "            print(f'Error: Went wrong with {city}')\n",
    "            result = None\n",
    "    except Exception:\n",
    "        result = None\n",
    "    \n",
    "    # Обновляем кэш\n",
    "    cache[city] = result\n",
    "    return result\n",
    "\n",
    "\n",
    "def save_cache(cache):\n",
    "    # Сохранение кэша в файл\n",
    "    with open(CACHE_FILE, 'w', encoding='utf-8') as f:\n",
    "        json.dump(cache, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "333a638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = load_cache()\n",
    "mask = full_df.geo.isna()\n",
    "full_df.loc[mask, 'geo'] = full_df.loc[mask, 'city'].apply(lambda x: get_geopoints(x, cache))\n",
    "\n",
    "save_cache(cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ecdb4f",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Success: DataFrame saved\n"
     ]
    }
   ],
   "source": [
    "full_df.to_csv('resources/full_df.csv')\n",
    "print('✔ Success: DataFrame saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b2935c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Success: DataFrame saved to YandexDisc\n"
     ]
    }
   ],
   "source": [
    "full_df.to_excel(PATH_TO_YANDEXDISC+'\\\\my.xlsx')\n",
    "print('✔ Success: DataFrame saved to YandexDisc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
